{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CMPUT 466/566, Winter 2020 Introduction to Machine learning \n",
    "## Coding Assignment 2 \n",
    "### Problem 1 Report\n",
    "By Nathan Klapstein #1449872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import struct\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def readMNISTdata():\n",
    "    with open('data/t10k-images-idx3-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "        test_data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        test_data = test_data.reshape((size, nrows * ncols))\n",
    "\n",
    "    with open('data/t10k-labels-idx1-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        test_labels = np.fromfile(f,\n",
    "                                  dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        test_labels = test_labels.reshape((size, 1))\n",
    "\n",
    "    with open('data/train-images-idx3-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "        train_data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        train_data = train_data.reshape((size, nrows * ncols))\n",
    "\n",
    "    with open('data/train-labels-idx1-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        train_labels = np.fromfile(f,\n",
    "                                   dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        train_labels = train_labels.reshape((size, 1))\n",
    "\n",
    "    # augmenting a constant feature of 1 (absorbing the bias term)\n",
    "    train_data = np.concatenate(\n",
    "        (np.ones([train_data.shape[0], 1]), train_data), axis=1)\n",
    "    test_data = np.concatenate((np.ones([test_data.shape[0], 1]), test_data),\n",
    "                               axis=1)\n",
    "    np.random.seed(314)\n",
    "    np.random.shuffle(train_labels)\n",
    "    np.random.seed(314)\n",
    "    np.random.shuffle(train_data)\n",
    "\n",
    "    X_train = train_data[:50000] / 256\n",
    "    t_train = train_labels[:50000]\n",
    "\n",
    "    X_val = train_data[50000:] / 256\n",
    "    t_val = train_labels[50000:]\n",
    "\n",
    "    return X_train, t_train, X_val, t_val, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, t_train, X_val, t_val, X_test, t_test = readMNISTdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, W, t=None):\n",
    "    # X_new: Nsample x (d+1)\n",
    "    # W: (d+1) x K\n",
    "\n",
    "    # TODO: Your code here\n",
    "#     print(X, \"w\" W, t)\n",
    "    \n",
    "    # TODO: recycled code\n",
    "#     y_hat = np.matmul(X, W)\n",
    "#     loss = (1 / 2) * np.average(np.square(y_hat - y))\n",
    "#     risk = np.average(np.abs(y_hat - y))\n",
    "\n",
    "    t_hat = np.matmul(X, W)\n",
    "    loss = (1 / 2) * np.average(np.square(t_hat - t))\n",
    "    risk = np.average(np.abs(t_hat - t))\n",
    "    # TODO: check if risk = acc\n",
    "    acc = risk\n",
    "    \n",
    "    return y, t_hat, loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(X_train, y_train, X_val, t_val):\n",
    "    N_train = X_train.shape[0]\n",
    "    N_val = X_val.shape[0]\n",
    "\n",
    "    # TODO: Your code here\n",
    "\n",
    "    return epoch_best, acc_best, W_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient(X, w, y=None):\n",
    "    # TODO: FIX:\n",
    "    # TODO: FIX:  Did not scale gradient by 1/M;\n",
    "    # TODO: FIX:\n",
    "    return np.matmul(np.transpose(X), (np.matmul(X, w) - y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# TODO: recycled code\n",
    "def train(X_train, y_train, X_val, y_val):\n",
    "    N_train = X_train.shape[0]\n",
    "    N_val = X_val.shape[0]\n",
    "\n",
    "    # initialization\n",
    "    w = np.zeros([X_train.shape[1], 1])\n",
    "    # w: (d+1)x1\n",
    "\n",
    "    losses_train = []\n",
    "    risks_val = []\n",
    "\n",
    "    w_best = None\n",
    "    risk_best = 10000\n",
    "    epoch_best = 0\n",
    "\n",
    "    for epoch in range(MaxIter):\n",
    "        loss_this_epoch = 0\n",
    "        for b in range(int(np.ceil(N_train / batch_size))):\n",
    "            X_batch = X_train[b * batch_size: (b + 1) * batch_size]\n",
    "            y_batch = y_train[b * batch_size: (b + 1) * batch_size]\n",
    "            # TODO: FIX:\n",
    "            # TODO: FIX: Did not scale gradient by 1/M;\n",
    "            # TODO: FIX:\n",
    "            y_hat_batch, loss_batch, risk = predict(X_batch, w, y_batch)\n",
    "            loss_this_epoch += loss_batch\n",
    "\n",
    "            # TODO: Your code here\n",
    "            # Mini-batch gradient descent\n",
    "            w = w - alpha * gradient(X_batch, w, y_batch)\n",
    "        #             print( \"weight : \" , w)\n",
    "        #             print(\"loss_batch: \" ,loss_batch)\n",
    "        #             print(\"risk:\" ,risk)\n",
    "\n",
    "        # TODO: Your code here\n",
    "        # monitor model behavior after each epoch\n",
    "        \n",
    "        # 1. Compute the training loss by averaging loss_this_epoch\n",
    "        #         losses_train.append(loss_this_epoch/int(np.ceil(N_train/batch_size)))\n",
    "        losses_train.append(loss_this_epoch / (int(np.ceil(N_train / batch_size))))\n",
    "        #print(f\"epoch={epoch} training loss={loss_this_epoch/  (int(np.ceil(N_train/batch_size)))}\")\n",
    "\n",
    "        # 2. Perform validation on the validation test by the risk\n",
    "        risk_this_epoch = 0\n",
    "        # TODO: FIX:\n",
    "        # TODO: FIX: Validation set should not be run in batches\n",
    "        # TODO: FIX:\n",
    "        for c in range(int(np.ceil(N_val / batch_size))):\n",
    "            X_val_batch = X_val[c * batch_size: (c + 1) * batch_size]\n",
    "            y_val_batch = y_val[c * batch_size: (c + 1) * batch_size]\n",
    "            _, _, risk = predict(X_val_batch, w, y_val_batch)\n",
    "            risk_this_epoch += risk\n",
    "        risks_val.append(risk_this_epoch / int(np.ceil(N_val / batch_size)))\n",
    "        #print(f\"epoch={epoch} risk={risk_this_epoch/int(np.ceil(N_val/batch_size))}\")\n",
    "        \n",
    "        # 3. Keep track of the best validation epoch, risk, and the weights\n",
    "        if risks_val[epoch] <= risk_best:\n",
    "            epoch_best = epoch\n",
    "            risk_best = risks_val[epoch]\n",
    "            w_best = w\n",
    "\n",
    "    # Return some variables as needed\n",
    "    return epoch_best, risk_best, w_best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 785) (50000, 1) (10000, 785) (10000, 1) (10000, 785) (10000, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5c1dc47e4a57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdecay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m  \u001b[1;31m# weight decay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mepoch_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-5ab95856f72f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# TODO: FIX: Did not scale gradient by 1/M;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0my_hat_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrisk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mloss_this_epoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-527d6f67c549>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X, W, t)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrisk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, t_train, X_val, t_val, X_test, t_test = readMNISTdata()\n",
    "\n",
    "print(X_train.shape, t_train.shape, X_val.shape, t_val.shape, X_test.shape,\n",
    "  t_test.shape)\n",
    "\n",
    "N_class = 10\n",
    "\n",
    "alpha = 0.1  # learning rate\n",
    "batch_size = 100  # batch size\n",
    "MaxIter = 50  # Maximum iteration\n",
    "decay = 0.  # weight decay\n",
    "\n",
    "epoch_best, acc_best, W_best = train(X_train, t_train, X_val, t_val)\n",
    "\n",
    "_, _, _, acc_test = predict(X_test, W_best, t_test)\n",
    "\n",
    "print('At epoch', epoch_best, 'val: ', acc_best, 'test:', acc_test, 'train:', acc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}